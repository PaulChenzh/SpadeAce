1. 什么是Tick Data
Tick Data本身并不神秘，就是交易所把每只股票（亦或是futures options）的active order book(就是你的委托还存在在交易所里面，但并且没有被撮合成交)里面的买、卖的单的情况发给你。
Tickey

2. HDF(Hierarchical Data Format),可以存储不同类型的图像和数码数据的文件格式，并且可以在不同类型的机器上传输，同时还有统一处理这种文件格式的函数库。
HDF5

3.kdb 是专门用于执行系统转储映像分析的实用工具
多用于Quant
https://www.ibm.com/developerworks/cn/aix/library/au-kdbsteps/

4.深度学习
https://zhuanlan.zhihu.com/p/24768878?refer=zhangbingyang

5.AI情况调研
http://www.sohu.com/a/138305708_465975

20170706
1.PCA 主成分分析
https://my.oschina.net/gujianhan/blog/225241

2.Deep Learning
http://deeplearning.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B
https://zhuanlan.zhihu.com/p/24768878?refer=zhangbingyang
http://www.cnblogs.com/tornadomeet/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/default.html?page=1

20170707
1.二元线性回归
http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=DeepLearning&doc=exercises/ex2/ex2.html

2.卷积神经网络（CNN，Convolutional Neural Network）
http://www.cnblogs.com/GarfieldEr007/p/5342906.html

3.深度学习导论
这里，先推荐一篇非常不错的文章： 《1天搞懂深度学习》，300多页的ppt，台湾李宏毅教授写的，非常棒。 不夸张地说，是我看过最系统，也最通俗易懂的，关于深度学习的文章。

这是slideshare的链接： http://www.slideshare.net/tw_dsconf/ss-62245351?qid=108adce3-2c3d-4758-a830-95d0a57e46bc&amp;v=&amp;b=&amp;from_search=3

作者：jacky yang
链接：https://www.zhihu.com/question/26006703/answer/129209540
来源：知乎
著作权归作者所有，转载请联系作者获得授权。


4.
这位爱好者把151只精灵宝可梦都做成了《炉石传说》卡牌
http://link.zhihu.com/?target=https%3A//imgur.com/a/hbNxg

5.十个值得一试的开源深度学习框架
http://www.oschina.net/news/68074/ten-worth-a-try-open-deep-learning-framework

20170710
1. TensorFlow - Github
https://github.com/tensorflow/tensorflow
2. TensorFlow - 中文网站
http://www.tensorfly.cn/
3.负载均衡器
Nginx - 软件
F5 - 硬件
http://www.cnblogs.com/brookzhang/p/6600861.html
4. 优雅降级(Graceful degradation)是指电脑，机器，电子系统或者是网络在本身大部分已经毁坏或无效的情况下还能保持有限的功能这种能力。优雅降级的目的是阻止灾难性的失败。理想情况下，有优雅降级特征的系统即使多个组件同时失效也不会引起停机。在优雅降级中，操作的效率和速度随着失效部件的增加逐渐下降。
5.大型网站架构系列
http://www.cnblogs.com/itfly8/p/5155983.html
https://www.zhihu.com/topic/19570823/top-answers
6.常用消息队列
一般商用的容器，比如WebLogic，JBoss，都支持JMS标准，开发上很方便。但免费的比如Tomcat，Jetty等则需要使用第三方的消息中间件。本部分内容介绍常用的消息中间件（Active MQ,Rabbit MQ，Zero MQ,Kafka）以及他们的特点。
7.Spring2.0的特性是什么？
8.告诉你Hadoop是什么
http://os.51cto.com/art/201207/346023.htm
9.Hadoop开篇必读
http://blog.fens.me/hadoop-family-roadmap/
10.DataCastle
秋小白
2 人赞同了该回答
去做DataCastle上面的竞赛题吧~
一般都是公司在实际运作中遇到的问题，然后放到这个竞赛平台上来让专业的人解决
在做竞赛中才能知道哪些需要更多的补充
11.开源机器学习框架
http://www.dataguru.cn/thread-601710-1-1.html
12.CTR（Click-Through-Rate）即点击通过率，是互联网广告常用的术语，指网络广告（图片广告/文字广告/关键词广告/排名广告/视频广告等）的点击到达率，即该广告的实际点击次数（严格的来说，可以是到达目标页面的数量）除以广告的展现量（Show content）。
13.机器学习面试的那些事儿
https://zhuanlan.zhihu.com/p/22387312
14.机器学习面试
https://www.zhihu.com/question/23259302
15.从0开始TensorFlow
https://www.leiphone.com/news/201606/ORlQ7uK3TIW8xVGF.html

20170711
1.round-robin 轮询调度
2.显式分布式架构
3.kafka
http://blog.jobbole.com/75328/
https://zhuanlan.zhihu.com/p/25212966
http://www.cnblogs.com/likehua/p/3999538.html
Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消费。
-- what is Kafka
Kafka是可靠的分布式日志存储服务。
用简单的话来说，你可以把Kafka当作可顺序写入的一大卷磁带， 可以随时倒带，快进到某个时间点重放。
作者：傅理
链接：https://www.zhihu.com/question/22480085/answer/135092014
来源：知乎
著作权归作者所有，转载请联系作者获得授权。

Kafka的特征如下：

高写入速度：Kafka能以超过1Gbps NIC的速度写这盘磁带（实际可以到SATA 3速度，参考Benchmarking Apache Kafka: 2 Million Writes Per Second (On Three Cheap Machines)
)，充分利用了磁盘的物理特性，即，随机写入慢（磁头冲停），顺序写入快（磁头悬浮）。

高可靠性： 通过zookeeper做分布式一致性，同步到任意多块磁盘上，故障自动切换选主，自愈。

高容量：通过横向扩展，LinkedIn每日通过Kafka存储的新增数据高达175TB，8000亿条消息，可无限扩容，类似把两条磁带粘到一起。

传统业务数据库的根本缺陷在于：
1. 太慢，读写太昂贵，无法避免的随机寻址。（磁盘最快5ms寻址，固态又太昂贵。）
2. 根本无法适应持续产生的数据流，越用越慢。（索引效率问题）
3. 无法水平scale。（多半是读写分离，一主多备。另: NewSQL通过一致性算法，有多主。）

针对这些问题，Kafka提出了一种方法: 

“log-centric approach（以日志为中心的方法）。”

将传统数据库分为两个独立的系统，即日志系统和索引系统。

“持久化和索引分开，日志尽可能快的落地，索引按照自己的速度追赶。”

在数据可靠性在得到Kafka这种快速的，类似磁带顺序记录方式保障的大前提下。数据的呈现，使用方式变得非常灵活，可以根据需要将数据流同时送入搜索系统，RDBMS系统，数据仓库系统， 图数据库系统，日志分析等这些各种不同的数据库系统。 这些不同的系统只不过是一种对Kafka磁带数据的一种诠释，一个侧面，一个索引，一个快照。数据丢了，没关系，重放一遍磁带即可，更多的时候，对这些各式数据库系统的维护只是需要定期做一个快照，并拷贝到一个安全的对象存储(如S3) 而已。 

一句话：“日志都是相同的日志，索引各有各的不同。”

以上故事说明了Kafka主要用途是数据集成，或者说是流数据集成，以Pub/Sub形式的消息总线形式提供。但是，Kafka不仅仅是一套传统的消息总线，本质上Kafka是分布式的流数据平台，因为以下特性而著名：

提供Pub/Sub方式的海量消息处理。
以高容错的方式存储海量数据流。
保证数据流的顺序。
4.Hadoop/Spark
Hadoop -> HDFS分布式数据存储 + MapReduce
	Hadoop解决了大数据（大到一台计算机无法进行存储，一台计算机无法在要求的时间内进行处理）的可靠存储和处理。
		HDFS，在由普通PC组成的集群上提供高可靠的文件存储，通过将块保存多个副本的办法解决服务器或硬盘坏掉的问题。
		MapReduce，通过简单的Mapper和Reducer的抽象提供一个编程模型，
		Apache Pig解决了MapRedude存在的大量手写代码，语义隐藏，提供操作种类少的问题，类似的项目还有Cascading,JAQL等。
Spark-大数据处理引擎，主要特点是提供了一个集群的分布式内存抽象。

Spark没有文件管理系统，所以，它必须和其他的分布式文件系统进行集成才能运作。
但Spark数据处理速度秒杀MapReduce。Spark的批处理速度比MapReduce快近10倍，内存中的数据分析速度则快近100倍。
-> Spark处理+Hadoop的HDFS分布式数据存储
what is MapReduce?
我们要数图书馆中的所有书。你数1号书架，我数2号书架。这就是“Map”。我们人越多，数书就更快。
现在我们到一起，把所有人的统计数加在一起。这就是“Reduce”。

深入理解Hadoop集群
http://os.51cto.com/art/201211/364374.htm

5.Paul got promoted to be an assistant manager in 2017. He proved himself for the qualification with good work performance. Job well done and looking forward to seeing him more success in 2017. 

20170712
1.如何快速成为数据分析师
https://www.zhihu.com/question/29265587

20170717
1. Spark实战
http://www.cnblogs.com/shishanyuan/p/4699644.html
	1.1 一个三个节点的集群
	a.操作系统：CentOS6.5 64bit
	b.Linux传输工具:SSH Secure File Transfer
	c.Linux命令行执行工具：SSH Secure Shell, SecureCRT
	2.配置运行环境
	a. 更新OpenSSL #yum update openssl
	b. 修改SSH配置文件
	c. 增加 hadoop组和用户
	d. JDK1.7 http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html
	打开界面之后，先选中 Accept License Agreement ，然后下载 jdk-7u55-linux-x64.tar.gz，如下图所示：
	e. Scala安装包 Scala2.10.4安装包下载链接为：http://www.scala-lang.org/download/2.10.4.html
	3.配置集群环境
	4....
2. 编译Hadoop
	1.环境配置
		1.maven http://mirror.bit.edu.cn/apache/maven/maven-3/
		2.SVN #yum install svn
		3.autoconf automake libtool cmake #yum install autoconf automake libtool cmake
		4.ncurses-devel #yum install ncurses-devel
		5.openssl-devel #yum install openssl-devel
		6.gcc* #yum install gcc*
		7.protobuf https://code.google.com/p/protobuf/downloads/list
	2.编译Hadoop
		1.Hadoop源码 Release2.2.0 $svn checkout http://svn.apache.org/repos/asf/hadoop/common/tags/release-2.2.0
		2.编译Hadoop源码 $mvn package -Pdist,native -DskipTests –Dtar
		3.验证编译是否成功
	3.安装Hadoop
		1.在主节点上压缩 
		$cd /home/hadoop/upload/
		$tar -xzf hadoop-2.2.0.tar.gz
		2. 把hadoop-2.2.0目录移到/app/hadoop目录下
2. Storm实时分布式系统
